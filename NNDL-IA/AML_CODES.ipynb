{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#semi supervised learning\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class SelfLearningModel(BaseEstimator):\n",
    "    def __init__(self, basemodel, max_iter=200, prob_threshold=0.8):\n",
    "        self.model = basemodel\n",
    "        self.max_iter = max_iter\n",
    "        self.prob_threshold = prob_threshold\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        labeled_mask = y != -1\n",
    "        labeled_X, labeled_y = X[labeled_mask], y[labeled_mask]\n",
    "        unlabeled_X = X[~labeled_mask]\n",
    "        self.model.fit(labeled_X, labeled_y)\n",
    "        \n",
    "        for _ in range(self.max_iter):\n",
    "            unlabeled_y = self.model.predict(unlabeled_X)\n",
    "            unlabeled_prob = np.max(self.model.predict_proba(unlabeled_X), axis=1)\n",
    "            confident_indices = unlabeled_prob > self.prob_threshold\n",
    "            if not np.any(confident_indices):\n",
    "                break\n",
    "            labeled_X = np.vstack([labeled_X, unlabeled_X[confident_indices]])\n",
    "            labeled_y = np.hstack([labeled_y, unlabeled_y[confident_indices]])\n",
    "            unlabeled_X = unlabeled_X[~confident_indices]\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9666666666666667\n",
      "Random Forest Accuracy: 0.9833333333333333\n",
      "Extra Trees Accuracy: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree, Random Forest, and Extremely Randomized Trees\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize the classifiers\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "et_classifier = ExtraTreesClassifier(n_estimators=90, random_state=42)\n",
    "\n",
    "# Train the classifiers\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "et_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "dt_pred = dt_classifier.predict(X_test)\n",
    "rf_pred = rf_classifier.predict(X_test)\n",
    "et_pred = et_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracies\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "et_accuracy = accuracy_score(y_test, et_pred)\n",
    "\n",
    "# Print the accuracies\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Extra Trees Accuracy:\", et_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohansridhar/miniforge3/envs/google/lib/python3.10/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# adaboost \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the base estimator (weak learner)\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Initialize the AdaBoost classifier with DecisionTreeClassifier as the base estimator\n",
    "ab_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the AdaBoost classifier\n",
    "ab_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "ab_pred = ab_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "ab_accuracy = accuracy_score(y_test, ab_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"AdaBoost Accuracy:\", ab_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " @Flip how are you not ded\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "text = \"\"\"\\xa0@Flip\\xa0how are you not ded\"\"\"\n",
    "\n",
    "# Use BeautifulSoup to handle the special characters\n",
    "soup = BeautifulSoup(text, \"html.parser\")\n",
    "clean_text = soup.get_text()\n",
    "\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Send your feedback to _EM or contact us at _EM\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def replace_emails(text):\n",
    "    email_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    return re.sub(email_regex, '_EM', text)\n",
    "\n",
    "text = \"Send your feedback to example@email.com or contact us at info@company.com\"\n",
    "cleaned_text = replace_emails(text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This',), ('is',), ('a',), ('sample',), ('text',), ('for',), ('generating',), ('unigrams',), ('.',)]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Sample text\n",
    "text = \"This is a sample text for generating unigrams.\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Generate unigrams\n",
    "unigrams = list(ngrams(words, 1))\n",
    "\n",
    "print(unigrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "google",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
